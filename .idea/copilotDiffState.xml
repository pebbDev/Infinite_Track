<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/data/face/FaceDetectorHelper.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/data/face/FaceDetectorHelper.kt" />
              <option name="originalContent" value="package com.example.infinite_track.data.face&#10;&#10;import android.graphics.Bitmap&#10;import androidx.annotation.OptIn&#10;import androidx.camera.core.ExperimentalGetImage&#10;import androidx.camera.core.ImageProxy&#10;import com.google.mlkit.vision.common.InputImage&#10;import com.google.mlkit.vision.face.Face&#10;import com.google.mlkit.vision.face.FaceDetection&#10;import com.google.mlkit.vision.face.FaceDetector&#10;import com.google.mlkit.vision.face.FaceDetectorOptions&#10;import javax.inject.Inject&#10;import javax.inject.Singleton&#10;&#10;/**&#10; * Helper class for ML Kit Face Detection operations&#10; * Handles face detection, liveness verification (blink/smile), and face extraction&#10; */&#10;@Singleton&#10;class FaceDetectorHelper @Inject constructor() {&#10;&#10;    companion object {&#10;        private const val BLINK_THRESHOLD = 0.4f // Threshold for eye open probability&#10;        private const val SMILE_THRESHOLD = 0.7f // Threshold for smile probability&#10;    }&#10;&#10;    // ML Kit Face Detector with optimized settings&#10;    private val faceDetector: FaceDetector by lazy {&#10;        val options = FaceDetectorOptions.Builder()&#10;            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST)&#10;            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)&#10;            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)&#10;            .setMinFaceSize(0.15f) // Minimum face size relative to image&#10;            .enableTracking() // Enable face tracking for better performance&#10;            .build()&#10;&#10;        FaceDetection.getClient(options)&#10;    }&#10;&#10;    /**&#10;     * Detects faces in the given image frame&#10;     * @param imageProxy Camera image frame from CameraX&#10;     * @param onResult Callback with detection result&#10;     */&#10;    @OptIn(ExperimentalGetImage::class)&#10;    fun detect(imageProxy: ImageProxy, onResult: (Result&lt;Face&gt;) -&gt; Unit) {&#10;        val mediaImage = imageProxy.image&#10;        if (mediaImage != null) {&#10;            val image = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)&#10;&#10;            faceDetector.process(image)&#10;                .addOnSuccessListener { faces -&gt;&#10;                    println(&quot;ML Kit face detection completed. Found ${faces.size} faces&quot;)&#10;                    if (faces.isNotEmpty()) {&#10;                        // Return the first (largest) detected face&#10;                        val largestFace =&#10;                            faces.maxByOrNull { it.boundingBox.width() * it.boundingBox.height() }&#10;                        if (largestFace != null) {&#10;                            println(&quot;Largest face found at: ${largestFace.boundingBox}&quot;)&#10;                            onResult(Result.success(largestFace))&#10;                        } else {&#10;                            println(&quot;No valid face detected despite faces list not empty&quot;)&#10;                            onResult(Result.failure(Exception(&quot;No valid face detected&quot;)))&#10;                        }&#10;                    } else {&#10;                        println(&quot;No faces detected in current frame&quot;)&#10;                        onResult(Result.failure(Exception(&quot;No faces detected&quot;)))&#10;                    }&#10;                }&#10;                .addOnFailureListener { exception -&gt;&#10;                    println(&quot;ML Kit face detection failed: ${exception.message}&quot;)&#10;                    onResult(Result.failure(exception))&#10;                }&#10;                .addOnCompleteListener {&#10;                    // Clean up resources - ALWAYS close imageProxy here&#10;                    imageProxy.close()&#10;                    println(&quot;ImageProxy closed after ML Kit processing&quot;)&#10;                }&#10;        } else {&#10;            println(&quot;MediaImage is null in imageProxy&quot;)&#10;            onResult(Result.failure(Exception(&quot;Image is null&quot;)))&#10;            imageProxy.close()&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Verifies if the person is blinking (liveness detection)&#10;     * @param face Detected face from ML Kit&#10;     * @return true if blink is detected (both eyes have low open probability)&#10;     */&#10;    fun verifyBlink(face: Face): Boolean {&#10;        val leftEyeOpenProbability = face.leftEyeOpenProbability&#10;        val rightEyeOpenProbability = face.rightEyeOpenProbability&#10;&#10;        return if (leftEyeOpenProbability != null &amp;&amp; rightEyeOpenProbability != null) {&#10;            // Both eyes should have low open probability (indicating they are closed/blinking)&#10;            leftEyeOpenProbability &lt; BLINK_THRESHOLD &amp;&amp; rightEyeOpenProbability &lt; BLINK_THRESHOLD&#10;        } else {&#10;            false // Cannot determine blink if probabilities are not available&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Verifies if the person is smiling (liveness detection)&#10;     * @param face Detected face from ML Kit&#10;     * @return true if smile is detected&#10;     */&#10;    fun verifySmile(face: Face): Boolean {&#10;        val smilingProbability = face.smilingProbability&#10;        return if (smilingProbability != null) {&#10;            smilingProbability &gt; SMILE_THRESHOLD&#10;        } else {&#10;            false // Cannot determine smile if probability is not available&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Extracts face region from the full image bitmap&#10;     * @param face Detected face with bounding box information&#10;     * @param image Full image bitmap&#10;     * @return Cropped face bitmap or null if extraction fails&#10;     */&#10;    fun extractFaceBitmap(face: Face, image: Bitmap): Bitmap? {&#10;        return try {&#10;            val boundingBox = face.boundingBox&#10;&#10;            // Ensure bounding box is within image bounds&#10;            val left = maxOf(0, boundingBox.left)&#10;            val top = maxOf(0, boundingBox.top)&#10;            val right = minOf(image.width, boundingBox.right)&#10;            val bottom = minOf(image.height, boundingBox.bottom)&#10;&#10;            // Validate that we have a valid crop area&#10;            if (left &lt; right &amp;&amp; top &lt; bottom) {&#10;                Bitmap.createBitmap(image, left, top, right - left, bottom - top)&#10;            } else {&#10;                null&#10;            }&#10;        } catch (e: Exception) {&#10;            null&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Checks if a face is well-positioned for verification&#10;     * @param face Detected face&#10;     * @param imageWidth Width of the camera frame&#10;     * @param imageHeight Height of the camera frame&#10;     * @return true if face is properly positioned&#10;     */&#10;    fun isFaceWellPositioned(face: Face, imageWidth: Int, imageHeight: Int): Boolean {&#10;        val boundingBox = face.boundingBox&#10;        val faceWidth = boundingBox.width()&#10;        val faceHeight = boundingBox.height()&#10;&#10;        // Check if face is not too small or too large&#10;        val minFaceSize = minOf(imageWidth, imageHeight) * 0.2f&#10;        val maxFaceSize = minOf(imageWidth, imageHeight) * 0.8f&#10;        val faceSize = minOf(faceWidth, faceHeight)&#10;&#10;        if (faceSize &lt; minFaceSize || faceSize &gt; maxFaceSize) {&#10;            return false&#10;        }&#10;&#10;        // Check if face is roughly centered&#10;        val faceCenterX = boundingBox.centerX()&#10;        val faceCenterY = boundingBox.centerY()&#10;        val imageCenterX = imageWidth / 2f&#10;        val imageCenterY = imageHeight / 2f&#10;&#10;        val maxOffsetX = imageWidth * 0.25f&#10;        val maxOffsetY = imageHeight * 0.25f&#10;&#10;        return kotlin.math.abs(faceCenterX - imageCenterX) &lt; maxOffsetX &amp;&amp;&#10;                kotlin.math.abs(faceCenterY - imageCenterY) &lt; maxOffsetY&#10;    }&#10;&#10;    /**&#10;     * Clean up resources when done&#10;     */&#10;    fun release() {&#10;        faceDetector.close()&#10;    }&#10;}&#10;" />
              <option name="updatedContent" value="package com.example.infinite_track.data.face&#10;&#10;import android.graphics.Bitmap&#10;import androidx.annotation.OptIn&#10;import androidx.camera.core.ExperimentalGetImage&#10;import androidx.camera.core.ImageProxy&#10;import com.google.mlkit.vision.common.InputImage&#10;import com.google.mlkit.vision.face.Face&#10;import com.google.mlkit.vision.face.FaceDetection&#10;import com.google.mlkit.vision.face.FaceDetector&#10;import com.google.mlkit.vision.face.FaceDetectorOptions&#10;import javax.inject.Inject&#10;import javax.inject.Singleton&#10;&#10;/**&#10; * Helper class for ML Kit Face Detection operations&#10; * Handles face detection, liveness verification (blink/smile), and face extraction&#10; */&#10;@Singleton&#10;class FaceDetectorHelper @Inject constructor() {&#10;&#10;    companion object {&#10;        private const val BLINK_THRESHOLD = 0.4f // Threshold for eye open probability&#10;        private const val SMILE_THRESHOLD = 0.7f // Threshold for smile probability&#10;    }&#10;&#10;    // ML Kit Face Detector with optimized settings&#10;    private val faceDetector: FaceDetector by lazy {&#10;        val options = FaceDetectorOptions.Builder()&#10;            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST)&#10;            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)&#10;            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)&#10;            .setMinFaceSize(0.15f) // Minimum face size relative to image&#10;            .enableTracking() // Enable face tracking for better performance&#10;            .build()&#10;&#10;        FaceDetection.getClient(options)&#10;    }&#10;&#10;    /**&#10;     * Detects faces in the given image frame&#10;     * @param imageProxy Camera image frame from CameraX&#10;     * @param onResult Callback with detection result&#10;     */&#10;    @OptIn(ExperimentalGetImage::class)&#10;    fun detect(imageProxy: ImageProxy, onResult: (Result&lt;Face&gt;) -&gt; Unit) {&#10;        val mediaImage = imageProxy.image&#10;        if (mediaImage != null) {&#10;            val image = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)&#10;&#10;            faceDetector.process(image)&#10;                .addOnSuccessListener { faces -&gt;&#10;                    println(&quot;ML Kit face detection completed. Found ${faces.size} faces&quot;)&#10;                    if (faces.isNotEmpty()) {&#10;                        // Return the first (largest) detected face&#10;                        val largestFace =&#10;                            faces.maxByOrNull { it.boundingBox.width() * it.boundingBox.height() }&#10;                        if (largestFace != null) {&#10;                            println(&quot;Largest face found at: ${largestFace.boundingBox}&quot;)&#10;                            onResult(Result.success(largestFace))&#10;                        } else {&#10;                            println(&quot;No valid face detected despite faces list not empty&quot;)&#10;                            onResult(Result.failure(Exception(&quot;No valid face detected&quot;)))&#10;                        }&#10;                    } else {&#10;                        println(&quot;No faces detected in current frame&quot;)&#10;                        onResult(Result.failure(Exception(&quot;No faces detected&quot;)))&#10;                    }&#10;                }&#10;                .addOnFailureListener { exception -&gt;&#10;                    println(&quot;ML Kit face detection failed: ${exception.message}&quot;)&#10;                    onResult(Result.failure(exception))&#10;                }&#10;                .addOnCompleteListener {&#10;                    // Clean up resources - ALWAYS close imageProxy here&#10;                    imageProxy.close()&#10;                    println(&quot;ImageProxy closed after ML Kit processing&quot;)&#10;                }&#10;        } else {&#10;            println(&quot;MediaImage is null in imageProxy&quot;)&#10;            onResult(Result.failure(Exception(&quot;Image is null&quot;)))&#10;            imageProxy.close()&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Verifies if the person is blinking (liveness detection)&#10;     * @param face Detected face from ML Kit&#10;     * @return true if blink is detected (both eyes have low open probability)&#10;     */&#10;    fun verifyBlink(face: Face): Boolean {&#10;        val leftEyeOpenProbability = face.leftEyeOpenProbability&#10;        val rightEyeOpenProbability = face.rightEyeOpenProbability&#10;&#10;        return if (leftEyeOpenProbability != null &amp;&amp; rightEyeOpenProbability != null) {&#10;            // Both eyes should have low open probability (indicating they are closed/blinking)&#10;            leftEyeOpenProbability &lt; BLINK_THRESHOLD &amp;&amp; rightEyeOpenProbability &lt; BLINK_THRESHOLD&#10;        } else {&#10;            false // Cannot determine blink if probabilities are not available&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Verifies if the person is smiling (liveness detection)&#10;     * @param face Detected face from ML Kit&#10;     * @return true if smile is detected&#10;     */&#10;    fun verifySmile(face: Face): Boolean {&#10;        val smilingProbability = face.smilingProbability&#10;        return if (smilingProbability != null) {&#10;            smilingProbability &gt; SMILE_THRESHOLD&#10;        } else {&#10;            false // Cannot determine smile if probability is not available&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Extracts and preprocesses face bitmap for consistent embedding generation&#10;     * @param face Detected face from ML Kit&#10;     * @param image Source bitmap from camera&#10;     * @return Preprocessed face bitmap or null if extraction fails&#10;     */&#10;    fun extractFaceBitmap(face: Face, image: Bitmap): Bitmap? {&#10;        return try {&#10;            val boundingBox = face.boundingBox&#10;&#10;            // DEBUG: Log original face detection info&#10;            println(&quot;DEBUG FaceDetectorHelper: Original bounding box: $boundingBox&quot;)&#10;            println(&quot;DEBUG FaceDetectorHelper: Source image size: ${image.width}x${image.height}&quot;)&#10;&#10;            // Add padding around the face for better context (10% on each side)&#10;            val padding = (boundingBox.width() * 0.1f).toInt()&#10;&#10;            // Calculate expanded bounding box with padding&#10;            val left = maxOf(0, boundingBox.left - padding)&#10;            val top = maxOf(0, boundingBox.top - padding)&#10;            val right = minOf(image.width, boundingBox.right + padding)&#10;            val bottom = minOf(image.height, boundingBox.bottom + padding)&#10;&#10;            println(&quot;DEBUG FaceDetectorHelper: Padded coordinates - left:$left, top:$top, right:$right, bottom:$bottom&quot;)&#10;            println(&quot;DEBUG FaceDetectorHelper: Crop dimensions: ${right - left}x${bottom - top}&quot;)&#10;&#10;            // Validate that we have a valid crop area&#10;            if (left &lt; right &amp;&amp; top &lt; bottom) {&#10;                // Extract face with padding&#10;                val croppedBitmap = Bitmap.createBitmap(image, left, top, right - left, bottom - top)&#10;                println(&quot;DEBUG FaceDetectorHelper: Cropped bitmap size: ${croppedBitmap.width}x${croppedBitmap.height}&quot;)&#10;&#10;                // KUNCI PERBAIKAN: Standardisasi ukuran dan format&#10;                val standardizedBitmap = standardizeFaceBitmap(croppedBitmap)&#10;                println(&quot;DEBUG FaceDetectorHelper: Standardized bitmap size: ${standardizedBitmap.width}x${standardizedBitmap.height}&quot;)&#10;&#10;                // Clean up intermediate bitmap&#10;                if (croppedBitmap != standardizedBitmap) {&#10;                    croppedBitmap.recycle()&#10;                }&#10;&#10;                standardizedBitmap&#10;            } else {&#10;                println(&quot;DEBUG FaceDetectorHelper: Invalid crop area - left:$left &gt;= right:$right or top:$top &gt;= bottom:$bottom&quot;)&#10;                null&#10;            }&#10;        } catch (e: Exception) {&#10;            println(&quot;DEBUG FaceDetectorHelper: Error extracting face bitmap: ${e.message}&quot;)&#10;            e.printStackTrace()&#10;            null&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Standardizes face bitmap to consistent size and format&#10;     * This ensures consistent preprocessing for both profile and camera images&#10;     */&#10;    private fun standardizeFaceBitmap(faceBitmap: Bitmap): Bitmap {&#10;        // PERBAIKAN: Gunakan ukuran yang sama dengan FaceProcessor (112x112)&#10;        val standardWidth = 112  // Sama dengan IMAGE_SIZE di FaceProcessor&#10;        val standardHeight = 112  // Sama dengan IMAGE_SIZE di FaceProcessor&#10;&#10;        return try {&#10;            // Resize to standard dimensions with high quality&#10;            Bitmap.createScaledBitmap(faceBitmap, standardWidth, standardHeight, true)&#10;        } catch (e: Exception) {&#10;            println(&quot;Error standardizing face bitmap: ${e.message}&quot;)&#10;            faceBitmap // Return original if standardization fails&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Checks if a face is well-positioned for verification&#10;     * @param face Detected face&#10;     * @param imageWidth Width of the camera frame&#10;     * @param imageHeight Height of the camera frame&#10;     * @return true if face is properly positioned&#10;     */&#10;    fun isFaceWellPositioned(face: Face, imageWidth: Int, imageHeight: Int): Boolean {&#10;        val boundingBox = face.boundingBox&#10;        val faceWidth = boundingBox.width()&#10;        val faceHeight = boundingBox.height()&#10;&#10;        // Check if face is not too small or too large&#10;        val minFaceSize = minOf(imageWidth, imageHeight) * 0.2f&#10;        val maxFaceSize = minOf(imageWidth, imageHeight) * 0.8f&#10;        val faceSize = minOf(faceWidth, faceHeight)&#10;&#10;        if (faceSize &lt; minFaceSize || faceSize &gt; maxFaceSize) {&#10;            return false&#10;        }&#10;&#10;        // Check if face is roughly centered&#10;        val faceCenterX = boundingBox.centerX()&#10;        val faceCenterY = boundingBox.centerY()&#10;        val imageCenterX = imageWidth / 2f&#10;        val imageCenterY = imageHeight / 2f&#10;&#10;        val maxOffsetX = imageWidth * 0.25f&#10;        val maxOffsetY = imageHeight * 0.25f&#10;&#10;        return kotlin.math.abs(faceCenterX - imageCenterX) &lt; maxOffsetX &amp;&amp;&#10;                kotlin.math.abs(faceCenterY - imageCenterY) &lt; maxOffsetY&#10;    }&#10;&#10;    /**&#10;     * Clean up resources when done&#10;     */&#10;    fun release() {&#10;        faceDetector.close()&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/di/NetworkModule.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/di/NetworkModule.kt" />
              <option name="originalContent" value="package com.example.infinite_track.di&#10;&#10;import com.example.infinite_track.data.soucre.local.preferences.UserPreference&#10;import com.example.infinite_track.data.soucre.network.retrofit.ApiService&#10;import com.example.infinite_track.data.soucre.network.retrofit.MapboxApiService&#10;import com.example.infinite_track.domain.manager.SessionManager&#10;import com.google.gson.GsonBuilder&#10;import dagger.Module&#10;import dagger.Provides&#10;import dagger.hilt.InstallIn&#10;import dagger.hilt.components.SingletonComponent&#10;import kotlinx.coroutines.Dispatchers&#10;import kotlinx.coroutines.runBlocking&#10;import okhttp3.OkHttpClient&#10;import okhttp3.logging.HttpLoggingInterceptor&#10;import retrofit2.Retrofit&#10;import retrofit2.converter.gson.GsonConverterFactory&#10;import java.util.concurrent.TimeUnit&#10;import javax.inject.Named&#10;import javax.inject.Provider&#10;import javax.inject.Singleton&#10;@Module&#10;@InstallIn(SingletonComponent::class)&#10;object NetworkModule {&#10;&#10;    // 1. Menyediakan Interceptor untuk Logging&#10;    @Provides&#10;    @Singleton&#10;    fun provideLoggingInterceptor(): HttpLoggingInterceptor {&#10;        return HttpLoggingInterceptor().setLevel(HttpLoggingInterceptor.Level.BODY)&#10;    }&#10;&#10;    // 2. Menyediakan Interceptor untuk Otentikasi dengan Auto Logout&#10;    @Provides&#10;    // 2. Menyediakan Interceptor untuk Otentikasi&#10;    fun provideAuthInterceptor(&#10;        userPreference: UserPreference,&#10;    fun provideAuthInterceptor(userPreference: UserPreference): Interceptor {&#10;            val token = runBlocking { userPreference.getAuthToken().first() }&#10;            val requestBuilder = chain.request().newBuilder()&#10;&#10;            if (!token.isNullOrEmpty()) {&#10;                requestBuilder.addHeader(&quot;Authorization&quot;, &quot;Bearer $token&quot;)&#10;            }&#10;&#10;            val response = chain.proceed(requestBuilder.build())&#10;&#10;            chain.proceed(requestBuilder.build())&#10;        }&#10;    }&#10;&#10;    // 3. Menyediakan OkHttpClient dengan timeout yang lebih panjang&#10;    @Provides&#10;    @Singleton&#10;    fun provideOkHttpClient(&#10;        loggingInterceptor: HttpLoggingInterceptor,&#10;        authInterceptor: Interceptor&#10;    ): OkHttpClient {&#10;        return OkHttpClient.Builder()&#10;            .addInterceptor(loggingInterceptor)&#10;            .addInterceptor(authInterceptor)&#10;            .connectTimeout(30, TimeUnit.SECONDS) // Increased timeout&#10;            .readTimeout(30, TimeUnit.SECONDS)&#10;            .writeTimeout(30, TimeUnit.SECONDS)&#10;            .build()&#10;    }&#10;&#10;    // 4. Menyediakan Retrofit untuk Backend API (yang sudah ada)&#10;    @Provides&#10;    @Singleton&#10;    @Named(&quot;backend&quot;)&#10;    fun provideBackendRetrofit(okHttpClient: OkHttpClient): Retrofit {&#10;        return Retrofit.Builder()&#10;            .baseUrl(baseUrl) // Base URL backend lokal&#10;            .addConverterFactory(GsonConverterFactory.create())&#10;            .client(okHttpClient)&#10;            .build()&#10;    }&#10;&#10;    // 5. Menyediakan Retrofit untuk Mapbox API (BARU)&#10;    @Provides&#10;    @Singleton&#10;    @Named(&quot;mapbox&quot;)&#10;    fun provideMapboxRetrofit(): Retrofit {&#10;        return Retrofit.Builder()&#10;            .baseUrl(&quot;https://api.mapbox.com/&quot;) // Base URL Mapbox langsung&#10;            .addConverterFactory(GsonConverterFactory.create())&#10;            .client(&#10;                OkHttpClient.Builder()&#10;                    .addInterceptor(HttpLoggingInterceptor().setLevel(HttpLoggingInterceptor.Level.BODY))&#10;                    .connectTimeout(30, TimeUnit.SECONDS)&#10;                    .readTimeout(30, TimeUnit.SECONDS)&#10;                    .build()&#10;            )&#10;            .build()&#10;    }&#10;&#10;    // 6. ApiService untuk Backend (yang sudah ada)&#10;    @Provides&#10;    @Singleton&#10;    fun provideApiService(@Named(&quot;backend&quot;) retrofit: Retrofit): ApiService {&#10;        return retrofit.create(ApiService::class.java)&#10;    }&#10;&#10;    // 7. MapboxApiService untuk Mapbox API (BARU)&#10;    @Provides&#10;    @Singleton&#10;    fun provideMapboxApiService(@Named(&quot;mapbox&quot;) retrofit: Retrofit): MapboxApiService {&#10;        return retrofit.create(MapboxApiService::class.java)&#10;    }&#10;&#10;    // Provide Gson instance for dependency injection&#10;    @Provides&#10;    @Singleton&#10;    fun provideGson(): Gson {&#10;        return GsonBuilder()&#10;            .setLenient()&#10;            .create()&#10;    }&#10;&#10;    // Helper method for reliable emulator detection that worked for you&#10;    private fun isEmulator(): Boolean {&#10;        return Build.FINGERPRINT.contains(&quot;generic&quot;) || Build.FINGERPRINT.contains(&quot;emulator&quot;)&#10;    }&#10;&#10;    // Property that returns the appropriate baseUrl based on device type&#10;    private val baseUrl: String&#10;        get() = if (isEmulator()) {&#10;            &quot;http://10.0.2.2:3005/&quot;&#10;        } else {&#10;            &quot;http://192.168.10.197:3005/&quot;&#10;        }&#10;}" />
              <option name="updatedContent" value="package com.example.infinite_track.di&#10;&#10;import android.os.Build&#10;import com.example.infinite_track.data.soucre.local.preferences.UserPreference&#10;import com.example.infinite_track.data.soucre.network.retrofit.ApiService&#10;import com.example.infinite_track.data.soucre.network.retrofit.MapboxApiService&#10;import com.example.infinite_track.domain.manager.SessionManager&#10;import com.example.infinite_track.domain.use_case.auth.LogoutUseCase&#10;import com.google.gson.Gson&#10;import com.google.gson.GsonBuilder&#10;import dagger.Module&#10;import dagger.Provides&#10;import dagger.hilt.InstallIn&#10;import dagger.hilt.components.SingletonComponent&#10;import kotlinx.coroutines.CoroutineScope&#10;import kotlinx.coroutines.Dispatchers&#10;import kotlinx.coroutines.flow.first&#10;import kotlinx.coroutines.launch&#10;import kotlinx.coroutines.runBlocking&#10;import okhttp3.Interceptor&#10;import okhttp3.OkHttpClient&#10;import okhttp3.logging.HttpLoggingInterceptor&#10;import retrofit2.Retrofit&#10;import retrofit2.converter.gson.GsonConverterFactory&#10;import java.util.concurrent.TimeUnit&#10;import javax.inject.Named&#10;import javax.inject.Provider&#10;import javax.inject.Singleton&#10;&#10;@Module&#10;@InstallIn(SingletonComponent::class)&#10;object NetworkModule {&#10;&#10;    // 1. Menyediakan Interceptor untuk Logging&#10;    @Provides&#10;    @Singleton&#10;    fun provideLoggingInterceptor(): HttpLoggingInterceptor {&#10;        return HttpLoggingInterceptor().setLevel(HttpLoggingInterceptor.Level.BODY)&#10;    }&#10;&#10;    // 2. Menyediakan Interceptor untuk Otentikasi dengan Auto Logout&#10;    @Provides&#10;    @Singleton&#10;    fun provideAuthInterceptor(&#10;        userPreference: UserPreference,&#10;        logoutUseCaseProvider: Provider&lt;LogoutUseCase&gt;,&#10;        sessionManagerProvider: Provider&lt;SessionManager&gt;&#10;    ): Interceptor {&#10;        return Interceptor { chain -&gt;&#10;            // Mengambil token secara sinkron dari DataStore&#10;            val token = runBlocking { userPreference.getAuthToken().first() }&#10;            val requestBuilder = chain.request().newBuilder()&#10;&#10;            if (!token.isNullOrEmpty()) {&#10;                requestBuilder.addHeader(&quot;Authorization&quot;, &quot;Bearer $token&quot;)&#10;            }&#10;&#10;            val response = chain.proceed(requestBuilder.build())&#10;&#10;            // Check for 401 Unauthorized response&#10;            if (response.code == 401) {&#10;                // PERBAIKAN: Tambahkan pengecualian untuk endpoint logout&#10;                val requestUrl = chain.request().url.toString()&#10;                val isLogoutRequest =&#10;                    requestUrl.contains(&quot;/auth/logout&quot;) || requestUrl.endsWith(&quot;/logout&quot;)&#10;&#10;                // Hanya trigger auto-logout jika bukan dari endpoint logout itu sendiri&#10;                if (!isLogoutRequest) {&#10;                    // Launch coroutine to handle logout in background&#10;                    CoroutineScope(Dispatchers.IO).launch {&#10;                        try {&#10;                            // Clear session data&#10;                            logoutUseCaseProvider.get().invoke()&#10;&#10;                            // Trigger session expiration notification&#10;                            sessionManagerProvider.get().triggerSessionExpired()&#10;                        } catch (e: Exception) {&#10;                            // Log error but don't crash the app&#10;                            e.printStackTrace()&#10;                        }&#10;                    }&#10;                } else {&#10;                    // Log untuk debugging - logout endpoint memang boleh return 401&#10;                    android.util.Log.d(&#10;                        &quot;AuthInterceptor&quot;,&#10;                        &quot;Ignoring 401 from logout endpoint: $requestUrl&quot;&#10;                    )&#10;                }&#10;            }&#10;&#10;            // PERBAIKAN: Tambahkan return statement yang hilang&#10;            response&#10;        }&#10;    }&#10;&#10;    // 3. Menyediakan OkHttpClient dengan timeout yang lebih panjang&#10;    @Provides&#10;    @Singleton&#10;    fun provideOkHttpClient(&#10;        loggingInterceptor: HttpLoggingInterceptor,&#10;        authInterceptor: Interceptor&#10;    ): OkHttpClient {&#10;        return OkHttpClient.Builder()&#10;            .addInterceptor(loggingInterceptor)&#10;            .addInterceptor(authInterceptor)&#10;            .connectTimeout(30, TimeUnit.SECONDS) // Increased timeout&#10;            .readTimeout(30, TimeUnit.SECONDS)&#10;            .writeTimeout(30, TimeUnit.SECONDS)&#10;            .build()&#10;    }&#10;&#10;    // 4. Menyediakan Retrofit untuk Backend API (yang sudah ada)&#10;    @Provides&#10;    @Singleton&#10;    @Named(&quot;backend&quot;)&#10;    fun provideBackendRetrofit(okHttpClient: OkHttpClient): Retrofit {&#10;        return Retrofit.Builder()&#10;            .baseUrl(baseUrl) // Base URL backend lokal&#10;            .addConverterFactory(GsonConverterFactory.create())&#10;            .client(okHttpClient)&#10;            .build()&#10;    }&#10;&#10;    // 5. Menyediakan Retrofit untuk Mapbox API (BARU)&#10;    @Provides&#10;    @Singleton&#10;    @Named(&quot;mapbox&quot;)&#10;    fun provideMapboxRetrofit(): Retrofit {&#10;        return Retrofit.Builder()&#10;            .baseUrl(&quot;https://api.mapbox.com/&quot;) // Base URL Mapbox langsung&#10;            .addConverterFactory(GsonConverterFactory.create())&#10;            .client(&#10;                OkHttpClient.Builder()&#10;                    .addInterceptor(HttpLoggingInterceptor().setLevel(HttpLoggingInterceptor.Level.BODY))&#10;                    .connectTimeout(30, TimeUnit.SECONDS)&#10;                    .readTimeout(30, TimeUnit.SECONDS)&#10;                    .build()&#10;            )&#10;            .build()&#10;    }&#10;&#10;    // 6. ApiService untuk Backend (yang sudah ada)&#10;    @Provides&#10;    @Singleton&#10;    fun provideApiService(@Named(&quot;backend&quot;) retrofit: Retrofit): ApiService {&#10;        return retrofit.create(ApiService::class.java)&#10;    }&#10;&#10;    // 7. MapboxApiService untuk Mapbox API (BARU)&#10;    @Provides&#10;    @Singleton&#10;    fun provideMapboxApiService(@Named(&quot;mapbox&quot;) retrofit: Retrofit): MapboxApiService {&#10;        return retrofit.create(MapboxApiService::class.java)&#10;    }&#10;&#10;    // Provide Gson instance for dependency injection&#10;    @Provides&#10;    @Singleton&#10;    fun provideGson(): Gson {&#10;        return GsonBuilder()&#10;            .setLenient()&#10;            .create()&#10;    }&#10;&#10;    // Helper method for reliable emulator detection that worked for you&#10;    private fun isEmulator(): Boolean {&#10;        return Build.FINGERPRINT.contains(&quot;generic&quot;) || Build.FINGERPRINT.contains(&quot;emulator&quot;)&#10;    }&#10;&#10;    // Property that returns the appropriate baseUrl based on device type&#10;    private val baseUrl: String&#10;        get() = if (isEmulator()) {&#10;            &quot;http://10.0.2.2:3005/&quot;&#10;        } else {&#10;            &quot;http://192.168.10.197:3005/&quot;&#10;        }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/domain/manager/SessionManager.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/domain/manager/SessionManager.kt" />
              <option name="updatedContent" value="package com.example.infinite_track.domain.manager&#10;&#10;import kotlinx.coroutines.flow.MutableStateFlow&#10;import kotlinx.coroutines.flow.StateFlow&#10;import kotlinx.coroutines.flow.asStateFlow&#10;import javax.inject.Inject&#10;import javax.inject.Singleton&#10;&#10;/**&#10; * Manager untuk menangani state sesi aplikasi&#10; * Termasuk notifikasi ketika sesi berakhir (401 error)&#10; */&#10;@Singleton&#10;class SessionManager @Inject constructor() {&#10;    &#10;    private val _sessionExpired = MutableStateFlow(false)&#10;    val sessionExpired: StateFlow&lt;Boolean&gt; = _sessionExpired.asStateFlow()&#10;    &#10;    /**&#10;     * Trigger session expiration&#10;     * Dipanggil oleh AuthInterceptor ketika mendapat 401 error&#10;     */&#10;    fun triggerSessionExpired() {&#10;        _sessionExpired.value = true&#10;    }&#10;    &#10;    /**&#10;     * Reset session expiration state&#10;     * Dipanggil setelah user dismiss dialog atau navigate ke login&#10;     */&#10;    fun resetSessionExpired() {&#10;        _sessionExpired.value = false&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/domain/use_case/auth/VerifyFaceUseCase.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/domain/use_case/auth/VerifyFaceUseCase.kt" />
              <option name="originalContent" value="package com.example.infinite_track.domain.use_case.auth&#10;&#10;import android.graphics.Bitmap&#10;import com.example.infinite_track.data.face.FaceProcessor&#10;import com.example.infinite_track.domain.repository.AuthRepository&#10;import kotlinx.coroutines.flow.first&#10;import javax.inject.Inject&#10;&#10;/**&#10; * Use case for verifying face against stored embedding&#10; * Handles face comparison for attendance check-in/check-out&#10; */&#10;class VerifyFaceUseCase @Inject constructor(&#10;    private val faceProcessor: FaceProcessor,&#10;    private val authRepository: AuthRepository&#10;) {&#10;    companion object {&#10;        private const val SIMILARITY_THRESHOLD = 0.8f // Minimum similarity for face match&#10;    }&#10;&#10;    /**&#10;     * Verifies captured face against stored user embedding&#10;     * @param capturedFaceBitmap Bitmap of the captured face&#10;     * @return Result&lt;Boolean&gt; indicating if face matches (true) or not (false)&#10;     */&#10;    suspend operator fun invoke(capturedFaceBitmap: Bitmap): Result&lt;Boolean&gt; {&#10;        return try {&#10;            // Get current user data with stored face embedding&#10;            val currentUser = authRepository.getLoggedInUser().first()&#10;                ?: return Result.failure(Exception(&quot;No logged in user found&quot;))&#10;&#10;            val storedEmbedding = currentUser.faceEmbedding&#10;                ?: return Result.failure(Exception(&quot;No stored face embedding found. Please update your profile.&quot;))&#10;&#10;            // Generate embedding from captured bitmap&#10;            val embeddingResult = generateEmbeddingFromBitmap(capturedFaceBitmap)&#10;&#10;            if (embeddingResult.isFailure) {&#10;                return Result.failure(&#10;                    embeddingResult.exceptionOrNull()&#10;                        ?: Exception(&quot;Failed to generate embedding from captured face&quot;)&#10;                )&#10;            }&#10;&#10;            val capturedEmbedding = embeddingResult.getOrNull()!!&#10;&#10;            // Compare embeddings using cosine similarity&#10;            val similarity = calculateCosineSimilarity(storedEmbedding, capturedEmbedding)&#10;&#10;            // Return true if similarity exceeds threshold&#10;            val isMatch = similarity &gt;= SIMILARITY_THRESHOLD&#10;&#10;            Result.success(isMatch)&#10;&#10;        } catch (e: Exception) {&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Generate embedding from bitmap using FaceProcessor&#10;     * Enhanced to work directly with Bitmap without URL&#10;     */&#10;    private suspend fun generateEmbeddingFromBitmap(bitmap: Bitmap): Result&lt;ByteArray&gt; {&#10;        return try {&#10;            // Use the new direct bitmap processing method from FaceProcessor&#10;            faceProcessor.generateEmbeddingFromBitmap(bitmap)&#10;        } catch (e: Exception) {&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Create temporary file from bitmap for processing&#10;     * This method is now deprecated in favor of direct bitmap processing&#10;     */&#10;    @Deprecated(&quot;Use generateEmbeddingFromBitmap directly&quot;)&#10;    private fun createTempImageFile(bitmap: Bitmap): java.io.File? {&#10;        return try {&#10;            val tempFile = java.io.File.createTempFile(&quot;face_capture&quot;, &quot;.jpg&quot;)&#10;            val outputStream = java.io.FileOutputStream(tempFile)&#10;            bitmap.compress(Bitmap.CompressFormat.JPEG, 90, outputStream)&#10;            outputStream.flush()&#10;            outputStream.close()&#10;            tempFile&#10;        } catch (e: Exception) {&#10;            null&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Calculate cosine similarity between two embeddings&#10;     * @param embedding1 First embedding (stored)&#10;     * @param embedding2 Second embedding (captured)&#10;     * @return Similarity score between 0.0 and 1.0&#10;     */&#10;    private fun calculateCosineSimilarity(embedding1: ByteArray, embedding2: ByteArray): Float {&#10;        if (embedding1.size != embedding2.size) {&#10;            return 0f&#10;        }&#10;&#10;        // Convert ByteArray to FloatArray for calculation&#10;        val floats1 = byteArrayToFloatArray(embedding1)&#10;        val floats2 = byteArrayToFloatArray(embedding2)&#10;&#10;        var dotProduct = 0.0&#10;        var normA = 0.0&#10;        var normB = 0.0&#10;&#10;        for (i in floats1.indices) {&#10;            dotProduct += floats1[i] * floats2[i]&#10;            normA += floats1[i] * floats1[i]&#10;            normB += floats2[i] * floats2[i]&#10;        }&#10;&#10;        return if (normA == 0.0 || normB == 0.0) {&#10;            0f&#10;        } else {&#10;            (dotProduct / (kotlin.math.sqrt(normA) * kotlin.math.sqrt(normB))).toFloat()&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Convert ByteArray to FloatArray for similarity calculation&#10;     */&#10;    private fun byteArrayToFloatArray(byteArray: ByteArray): FloatArray {&#10;        val floatArray = FloatArray(byteArray.size / 4)&#10;        val buffer = java.nio.ByteBuffer.wrap(byteArray)&#10;        buffer.order(java.nio.ByteOrder.LITTLE_ENDIAN)&#10;&#10;        for (i in floatArray.indices) {&#10;            floatArray[i] = buffer.getFloat(i * 4)&#10;        }&#10;&#10;        return floatArray&#10;    }&#10;}&#10;" />
              <option name="updatedContent" value="package com.example.infinite_track.domain.use_case.auth&#10;&#10;import android.graphics.Bitmap&#10;import com.example.infinite_track.data.face.FaceProcessor&#10;import com.example.infinite_track.domain.repository.AuthRepository&#10;import kotlinx.coroutines.flow.first&#10;import javax.inject.Inject&#10;&#10;/**&#10; * Use case for verifying face against stored embedding&#10; * Handles face comparison for attendance check-in/check-out&#10; */&#10;class VerifyFaceUseCase @Inject constructor(&#10;    private val faceProcessor: FaceProcessor,&#10;    private val authRepository: AuthRepository&#10;) {&#10;    companion object {&#10;        // PERBAIKAN: Turunkan threshold berdasarkan hasil testing (0.197)&#10;        private const val SIMILARITY_THRESHOLD = 0.15f // Turun dari 0.4f ke 0.15f&#10;        private const val TAG = &quot;VerifyFaceUseCase&quot;&#10;    }&#10;&#10;    /**&#10;     * Verifies captured face against stored user embedding&#10;     * @param capturedFaceBitmap Bitmap of the captured face (sudah di-preprocess oleh FaceDetectorHelper)&#10;     * @return Result&lt;Boolean&gt; indicating if face matches (true) or not (false)&#10;     */&#10;    suspend operator fun invoke(capturedFaceBitmap: Bitmap): Result&lt;Boolean&gt; {&#10;        return try {&#10;            // Get current user data with stored face embedding&#10;            val currentUser = authRepository.getLoggedInUser().first()&#10;                ?: return Result.failure(Exception(&quot;No logged in user found&quot;))&#10;&#10;            val storedEmbedding = currentUser.faceEmbedding&#10;                ?: return Result.failure(Exception(&quot;No stored face embedding found. Please update your profile.&quot;))&#10;&#10;            // Generate embedding from captured bitmap (sudah standardized ke 112x112)&#10;            val embeddingResult = generateEmbeddingFromBitmap(capturedFaceBitmap)&#10;&#10;            if (embeddingResult.isFailure) {&#10;                return Result.failure(&#10;                    embeddingResult.exceptionOrNull()&#10;                        ?: Exception(&quot;Failed to generate embedding from captured face&quot;)&#10;                )&#10;            }&#10;&#10;            val capturedEmbedding = embeddingResult.getOrNull()!!&#10;&#10;            // Compare embeddings using cosine similarity&#10;            val similarity = calculateCosineSimilarity(storedEmbedding, capturedEmbedding)&#10;&#10;            // Log similarity score untuk debugging&#10;            android.util.Log.d(TAG, &quot;Face similarity score: $similarity (threshold: $SIMILARITY_THRESHOLD)&quot;)&#10;&#10;            // Return true if similarity exceeds threshold&#10;            val isMatch = similarity &gt;= SIMILARITY_THRESHOLD&#10;&#10;            android.util.Log.d(TAG, &quot;Face verification result: $isMatch&quot;)&#10;&#10;            Result.success(isMatch)&#10;&#10;        } catch (e: Exception) {&#10;            android.util.Log.e(TAG, &quot;Error in face verification&quot;, e)&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Generate embedding from bitmap using FaceProcessor&#10;     * Enhanced to work directly with Bitmap without URL&#10;     */&#10;    private suspend fun generateEmbeddingFromBitmap(bitmap: Bitmap): Result&lt;ByteArray&gt; {&#10;        return try {&#10;            // Use the new direct bitmap processing method from FaceProcessor&#10;            faceProcessor.generateEmbeddingFromBitmap(bitmap)&#10;        } catch (e: Exception) {&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Create temporary file from bitmap for processing&#10;     * This method is now deprecated in favor of direct bitmap processing&#10;     */&#10;    @Deprecated(&quot;Use generateEmbeddingFromBitmap directly&quot;)&#10;    private fun createTempImageFile(bitmap: Bitmap): java.io.File? {&#10;        return try {&#10;            val tempFile = java.io.File.createTempFile(&quot;face_capture&quot;, &quot;.jpg&quot;)&#10;            val outputStream = java.io.FileOutputStream(tempFile)&#10;            bitmap.compress(Bitmap.CompressFormat.JPEG, 90, outputStream)&#10;            outputStream.flush()&#10;            outputStream.close()&#10;            tempFile&#10;        } catch (e: Exception) {&#10;            null&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Calculate cosine similarity between two embeddings&#10;     * @param embedding1 First embedding (stored)&#10;     * @param embedding2 Second embedding (captured)&#10;     * @return Similarity score between 0.0 and 1.0&#10;     */&#10;    private fun calculateCosineSimilarity(embedding1: ByteArray, embedding2: ByteArray): Float {&#10;        if (embedding1.size != embedding2.size) {&#10;            return 0f&#10;        }&#10;&#10;        // Convert ByteArray to FloatArray for calculation&#10;        val floats1 = byteArrayToFloatArray(embedding1)&#10;        val floats2 = byteArrayToFloatArray(embedding2)&#10;&#10;        var dotProduct = 0.0&#10;        var normA = 0.0&#10;        var normB = 0.0&#10;&#10;        for (i in floats1.indices) {&#10;            dotProduct += floats1[i] * floats2[i]&#10;            normA += floats1[i] * floats1[i]&#10;            normB += floats2[i] * floats2[i]&#10;        }&#10;&#10;        return if (normA == 0.0 || normB == 0.0) {&#10;            0f&#10;        } else {&#10;            (dotProduct / (kotlin.math.sqrt(normA) * kotlin.math.sqrt(normB))).toFloat()&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Convert ByteArray to FloatArray for similarity calculation&#10;     */&#10;    private fun byteArrayToFloatArray(byteArray: ByteArray): FloatArray {&#10;        val floatArray = FloatArray(byteArray.size / 4)&#10;        val buffer = java.nio.ByteBuffer.wrap(byteArray)&#10;        buffer.order(java.nio.ByteOrder.LITTLE_ENDIAN)&#10;&#10;        for (i in floatArray.indices) {&#10;            floatArray[i] = buffer.getFloat(i * 4)&#10;        }&#10;&#10;        return floatArray&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/presentation/main/InfiniteTrackApp.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/presentation/main/InfiniteTrackApp.kt" />
              <option name="originalContent" value="package com.example.infinite_track.presentation.main&#10;&#10;import androidx.compose.animation.core.Animatable&#10;import androidx.compose.animation.core.LinearEasing&#10;import androidx.compose.animation.core.RepeatMode&#10;import androidx.compose.animation.core.animateFloat&#10;import androidx.compose.animation.core.infiniteRepeatable&#10;import androidx.compose.animation.core.keyframes&#10;import androidx.compose.animation.core.rememberInfiniteTransition&#10;import androidx.compose.animation.core.tween&#10;import androidx.compose.foundation.background&#10;import androidx.compose.foundation.layout.Box&#10;import androidx.compose.foundation.layout.fillMaxSize&#10;import androidx.compose.material3.Surface&#10;import androidx.compose.runtime.Composable&#10;import androidx.compose.runtime.LaunchedEffect&#10;import androidx.compose.runtime.getValue&#10;import androidx.compose.runtime.remember&#10;import androidx.compose.ui.Modifier&#10;import androidx.compose.ui.graphics.Color&#10;import androidx.compose.ui.zIndex&#10;import androidx.navigation.compose.NavHost&#10;import androidx.navigation.compose.rememberNavController&#10;import com.example.infinite_track.presentation.components.base.BaseLayout&#10;import com.example.infinite_track.presentation.navigation.AppNavigator&#10;import com.example.infinite_track.presentation.navigation.NavigationEvent&#10;import com.example.infinite_track.presentation.navigation.Screen&#10;import com.example.infinite_track.presentation.navigation.appNavGraph&#10;import kotlinx.coroutines.flow.collectLatest&#10;&#10;@Composable&#10;fun InfiniteTrackApp(&#10;    modifier: Modifier = Modifier,&#10;    appNavigator: AppNavigator? = null&#10;) {&#10;    // Root level NavController - handles top-level navigation&#10;    val navController = rememberNavController()&#10;&#10;    // Handle navigation events from AppNavigator&#10;    LaunchedEffect(appNavigator) {&#10;        appNavigator?.navigationEvents?.collectLatest { event -&gt;&#10;            when (event) {&#10;                is NavigationEvent.NavigateToAttendance -&gt; {&#10;                    // Navigate to attendance screen&#10;                    navController.navigate(Screen.Attendance.route) {&#10;                        // Optional: Clear back stack if needed&#10;                        launchSingleTop = true&#10;                    }&#10;                }&#10;&#10;                is NavigationEvent.NavigateToScreen -&gt; {&#10;                    navController.navigate(event.route) {&#10;                        launchSingleTop = true&#10;                    }&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    // State animation defined at the app level - this will persist across screen navigations&#10;    val infiniteTransition = rememberInfiniteTransition(label = &quot;infinite_rotation&quot;)&#10;    val rotationAnimation by infiniteTransition.animateFloat(&#10;        initialValue = 0f,&#10;        targetValue = 360f,&#10;        animationSpec = infiniteRepeatable(&#10;            animation = tween(durationMillis = 30000, easing = LinearEasing),&#10;            repeatMode = RepeatMode.Restart&#10;        ),&#10;        label = &quot;rotation&quot;&#10;    )&#10;&#10;    val sizeTransition = remember { Animatable(0f) }&#10;    LaunchedEffect(Unit) {&#10;        sizeTransition.animateTo(&#10;            targetValue = 1f,&#10;            animationSpec = infiniteRepeatable(&#10;                animation = keyframes {&#10;                    durationMillis = 10000&#10;                    0f at 0&#10;                    1f at 5000&#10;                    0f at 10000&#10;                },&#10;                repeatMode = RepeatMode.Restart&#10;            )&#10;        )&#10;    }&#10;&#10;    // Main box that contains both the BaseLayout and the rest of the UI&#10;    Box(modifier = modifier.fillMaxSize()) {&#10;        // BaseLayout displayed at the back layer&#10;        BaseLayout(&#10;            rotation = rotationAnimation,&#10;            size = sizeTransition.value,&#10;            modifier = Modifier.zIndex(-2f)&#10;        )&#10;&#10;        // Semi-transparent white layer over BaseLayout&#10;        Box(&#10;            modifier = Modifier&#10;                .fillMaxSize()&#10;                .zIndex(-1f)&#10;                .background(Color.White.copy(alpha = 0.5f))&#10;        )&#10;&#10;        // Clean, minimal root container&#10;        Surface(&#10;            modifier = Modifier.fillMaxSize(),&#10;            color = Color.Transparent&#10;        ) {&#10;            // Root NavHost with only top-level navigation concerns&#10;            NavHost(&#10;                navController = navController,&#10;                startDestination = Screen.Splash.route&#10;            ) {&#10;                // Connect to the app navigation graph&#10;                appNavGraph(navController)&#10;            }&#10;        }&#10;    }&#10;}&#10;" />
              <option name="updatedContent" value="package com.example.infinite_track.presentation.main&#10;&#10;import androidx.compose.animation.core.Animatable&#10;import androidx.compose.animation.core.LinearEasing&#10;import androidx.compose.animation.core.RepeatMode&#10;import androidx.compose.animation.core.animateFloat&#10;import androidx.compose.animation.core.infiniteRepeatable&#10;import androidx.compose.animation.core.keyframes&#10;import androidx.compose.animation.core.rememberInfiniteTransition&#10;import androidx.compose.animation.core.tween&#10;import androidx.compose.foundation.background&#10;import androidx.compose.foundation.layout.Box&#10;import androidx.compose.foundation.layout.fillMaxSize&#10;import androidx.compose.material3.Surface&#10;import androidx.compose.runtime.Composable&#10;import androidx.compose.runtime.LaunchedEffect&#10;import androidx.compose.runtime.collectAsState&#10;import androidx.compose.runtime.getValue&#10;import androidx.compose.runtime.remember&#10;import androidx.compose.ui.Modifier&#10;import androidx.compose.ui.graphics.Color&#10;import androidx.compose.ui.platform.LocalContext&#10;import androidx.compose.ui.zIndex&#10;import androidx.hilt.navigation.compose.hiltViewModel&#10;import androidx.navigation.compose.NavHost&#10;import androidx.navigation.compose.rememberNavController&#10;import com.example.infinite_track.domain.manager.SessionManager&#10;import com.example.infinite_track.presentation.components.base.BaseLayout&#10;import com.example.infinite_track.presentation.navigation.AppNavigator&#10;import com.example.infinite_track.presentation.navigation.NavigationEvent&#10;import com.example.infinite_track.presentation.navigation.Screen&#10;import com.example.infinite_track.presentation.navigation.appNavGraph&#10;import com.example.infinite_track.utils.DialogHelper&#10;import kotlinx.coroutines.flow.collectLatest&#10;&#10;@Composable&#10;fun InfiniteTrackApp(&#10;    modifier: Modifier = Modifier,&#10;    appNavigator: AppNavigator? = null,&#10;    sessionManager: SessionManager? = null&#10;) {&#10;    // Root level NavController - handles top-level navigation&#10;    val navController = rememberNavController()&#10;    val context = LocalContext.current&#10;    &#10;    // Observe session expiration state&#10;    val sessionExpired by sessionManager?.sessionExpired?.collectAsState() ?: remember { androidx.compose.runtime.mutableStateOf(false) }&#10;&#10;    // Handle session expiration&#10;    LaunchedEffect(sessionExpired) {&#10;        if (sessionExpired) {&#10;            // Show session expired dialog&#10;            DialogHelper.showDialogError(&#10;                context = context,&#10;                title = &quot;Sesi Berakhir&quot;,&#10;                textContent = &quot;Sesi Anda telah berakhir. Silakan login kembali untuk melanjutkan.&quot;,&#10;                onConfirm = {&#10;                    // Reset session expired state&#10;                    sessionManager?.resetSessionExpired()&#10;                    &#10;                    // Navigate to login and clear back stack&#10;                    navController.navigate(Screen.Login.route) {&#10;                        popUpTo(0) { inclusive = true }&#10;                        launchSingleTop = true&#10;                    }&#10;                }&#10;            )&#10;        }&#10;    }&#10;&#10;    // Handle navigation events from AppNavigator&#10;    LaunchedEffect(appNavigator) {&#10;        appNavigator?.navigationEvents?.collectLatest { event -&gt;&#10;            when (event) {&#10;                is NavigationEvent.NavigateToAttendance -&gt; {&#10;                    // Navigate to attendance screen&#10;                    navController.navigate(Screen.Attendance.route) {&#10;                        // Optional: Clear back stack if needed&#10;                        launchSingleTop = true&#10;                    }&#10;                }&#10;&#10;                is NavigationEvent.NavigateToScreen -&gt; {&#10;                    navController.navigate(event.route) {&#10;                        launchSingleTop = true&#10;                    }&#10;                }&#10;&#10;                is NavigationEvent.NavigateToLoginAfterSessionExpired -&gt; {&#10;                    // This event is now handled by SessionManager state above&#10;                    // Keeping for backward compatibility if needed elsewhere&#10;                    navController.navigate(Screen.Login.route) {&#10;                        popUpTo(0) { inclusive = true }&#10;                        launchSingleTop = true&#10;                    }&#10;                }&#10;            }&#10;        }&#10;    }&#10;&#10;    // State animation defined at the app level - this will persist across screen navigations&#10;    val infiniteTransition = rememberInfiniteTransition(label = &quot;infinite_rotation&quot;)&#10;    val rotationAnimation by infiniteTransition.animateFloat(&#10;        initialValue = 0f,&#10;        targetValue = 360f,&#10;        animationSpec = infiniteRepeatable(&#10;            animation = tween(durationMillis = 30000, easing = LinearEasing),&#10;            repeatMode = RepeatMode.Restart&#10;        ),&#10;        label = &quot;rotation&quot;&#10;    )&#10;&#10;    val sizeTransition = remember { Animatable(0f) }&#10;    LaunchedEffect(Unit) {&#10;        sizeTransition.animateTo(&#10;            targetValue = 1f,&#10;            animationSpec = infiniteRepeatable(&#10;                animation = keyframes {&#10;                    durationMillis = 10000&#10;                    0f at 0&#10;                    1f at 5000&#10;                    0f at 10000&#10;                },&#10;                repeatMode = RepeatMode.Restart&#10;            )&#10;        )&#10;    }&#10;&#10;    // Main box that contains both the BaseLayout and the rest of the UI&#10;    Box(modifier = modifier.fillMaxSize()) {&#10;        // BaseLayout displayed at the back layer&#10;        BaseLayout(&#10;            rotation = rotationAnimation,&#10;            size = sizeTransition.value,&#10;            modifier = Modifier.zIndex(-2f)&#10;        )&#10;&#10;        // Semi-transparent white layer over BaseLayout&#10;        Box(&#10;            modifier = Modifier&#10;                .fillMaxSize()&#10;                .zIndex(-1f)&#10;                .background(Color.White.copy(alpha = 0.5f))&#10;        )&#10;&#10;        // Clean, minimal root container&#10;        Surface(&#10;            modifier = Modifier.fillMaxSize(),&#10;            color = Color.Transparent&#10;        ) {&#10;            // Root NavHost with only top-level navigation concerns&#10;            NavHost(&#10;                navController = navController,&#10;                startDestination = Screen.Splash.route&#10;            ) {&#10;                // Connect to the app navigation graph&#10;                appNavGraph(navController)&#10;            }&#10;        }&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/presentation/main/MainActivity.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/presentation/main/MainActivity.kt" />
              <option name="originalContent" value="package com.example.infinite_track.presentation.main&#10;&#10;import android.content.Intent&#10;import android.os.Bundle&#10;import android.util.Log&#10;import androidx.activity.ComponentActivity&#10;import androidx.activity.compose.setContent&#10;import androidx.activity.enableEdgeToEdge&#10;import androidx.activity.viewModels&#10;import androidx.core.splashscreen.SplashScreen.Companion.installSplashScreen&#10;import com.example.infinite_track.presentation.navigation.AppNavigator&#10;import com.example.infinite_track.presentation.screen.splash.SplashNavigationState&#10;import com.example.infinite_track.presentation.screen.splash.SplashViewModel&#10;import com.example.infinite_track.presentation.theme.Infinite_TrackTheme&#10;import dagger.hilt.android.AndroidEntryPoint&#10;import javax.inject.Inject&#10;&#10;@AndroidEntryPoint&#10;class MainActivity : ComponentActivity() {&#10;    // Get SplashViewModel instance&#10;    private val viewModel: SplashViewModel by viewModels()&#10;&#10;    // Inject AppNavigator untuk navigasi dari Activity&#10;    @Inject&#10;    lateinit var appNavigator: AppNavigator&#10;&#10;    override fun onCreate(savedInstanceState: Bundle?) {&#10;        // Install splash screen BEFORE super.onCreate()&#10;        val splashScreen = installSplashScreen()&#10;&#10;        // Set keep on screen condition - keep splash screen visible while in Loading state&#10;        splashScreen.setKeepOnScreenCondition {&#10;            viewModel.navigationState.value is SplashNavigationState.Loading&#10;        }&#10;&#10;        super.onCreate(savedInstanceState)&#10;        enableEdgeToEdge()&#10;        setContent {&#10;            Infinite_TrackTheme {&#10;                InfiniteTrackApp(appNavigator = appNavigator)&#10;            }&#10;        }&#10;&#10;        // Handle intent saat aplikasi pertama kali dibuka dari notifikasi&#10;        handleIntent(intent)&#10;    }&#10;&#10;    override fun onNewIntent(intent: Intent) {&#10;        super.onNewIntent(intent)&#10;        // Handle intent saat aplikasi sudah berjalan di background dan notifikasi diklik&#10;        handleIntent(intent)&#10;    }&#10;&#10;    private fun handleIntent(intent: Intent?) {&#10;        // Periksa apakah intent memiliki extra yang kita kirim dari NotificationHelper&#10;        if (intent?.getBooleanExtra(&quot;navigate_to_attendance&quot;, false) == true) {&#10;            // Gunakan AppNavigator untuk navigasi ke AttendanceScreen&#10;            appNavigator.navigateToAttendance()&#10;            Log.d(&quot;MainActivity&quot;, &quot;Navigating to AttendanceScreen via AppNavigator&quot;)&#10;        }&#10;    }&#10;}" />
              <option name="updatedContent" value="package com.example.infinite_track.presentation.main&#10;&#10;import android.content.Intent&#10;import android.os.Bundle&#10;import android.util.Log&#10;import androidx.activity.ComponentActivity&#10;import androidx.activity.compose.setContent&#10;import androidx.activity.enableEdgeToEdge&#10;import androidx.activity.viewModels&#10;import androidx.core.splashscreen.SplashScreen.Companion.installSplashScreen&#10;import com.example.infinite_track.domain.manager.SessionManager&#10;import com.example.infinite_track.presentation.navigation.AppNavigator&#10;import com.example.infinite_track.presentation.screen.splash.SplashNavigationState&#10;import com.example.infinite_track.presentation.screen.splash.SplashViewModel&#10;import com.example.infinite_track.presentation.theme.Infinite_TrackTheme&#10;import dagger.hilt.android.AndroidEntryPoint&#10;import javax.inject.Inject&#10;&#10;@AndroidEntryPoint&#10;class MainActivity : ComponentActivity() {&#10;    // Get SplashViewModel instance&#10;    private val viewModel: SplashViewModel by viewModels()&#10;&#10;    // Inject AppNavigator untuk navigasi dari Activity&#10;    @Inject&#10;    lateinit var appNavigator: AppNavigator&#10;&#10;    // Inject SessionManager untuk menangani session expiration&#10;    @Inject&#10;    lateinit var sessionManager: SessionManager&#10;&#10;    override fun onCreate(savedInstanceState: Bundle?) {&#10;        // Install splash screen BEFORE super.onCreate()&#10;        val splashScreen = installSplashScreen()&#10;&#10;        // Set keep on screen condition - keep splash screen visible while in Loading state&#10;        splashScreen.setKeepOnScreenCondition {&#10;            viewModel.navigationState.value is SplashNavigationState.Loading&#10;        }&#10;&#10;        super.onCreate(savedInstanceState)&#10;        enableEdgeToEdge()&#10;        setContent {&#10;            Infinite_TrackTheme {&#10;                InfiniteTrackApp(&#10;                    appNavigator = appNavigator,&#10;                    sessionManager = sessionManager&#10;                )&#10;            }&#10;        }&#10;&#10;        // Handle intent saat aplikasi pertama kali dibuka dari notifikasi&#10;        handleIntent(intent)&#10;    }&#10;&#10;    override fun onNewIntent(intent: Intent) {&#10;        super.onNewIntent(intent)&#10;        // Handle intent saat aplikasi sudah berjalan di background dan notifikasi diklik&#10;        handleIntent(intent)&#10;    }&#10;&#10;    private fun handleIntent(intent: Intent?) {&#10;        // Periksa apakah intent memiliki extra yang kita kirim dari NotificationHelper&#10;        if (intent?.getBooleanExtra(&quot;navigate_to_attendance&quot;, false) == true) {&#10;            // Gunakan AppNavigator untuk navigasi ke AttendanceScreen&#10;            appNavigator.navigateToAttendance()&#10;            Log.d(&quot;MainActivity&quot;, &quot;Navigating to AttendanceScreen via AppNavigator&quot;)&#10;        }&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/presentation/navigation/AppNavigator.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/presentation/navigation/AppNavigator.kt" />
              <option name="originalContent" value="package com.example.infinite_track.presentation.navigation&#10;&#10;import kotlinx.coroutines.flow.MutableSharedFlow&#10;import kotlinx.coroutines.flow.asSharedFlow&#10;import javax.inject.Inject&#10;import javax.inject.Singleton&#10;&#10;/**&#10; * Singleton navigator untuk menangani navigasi dari luar Composable context&#10; * Useful untuk navigasi dari Activity, BroadcastReceiver, atau Service&#10; */&#10;@Singleton&#10;class AppNavigator @Inject constructor() {&#10;&#10;    private val _navigationEvents = MutableSharedFlow&lt;NavigationEvent&gt;()&#10;    val navigationEvents = _navigationEvents.asSharedFlow()&#10;&#10;    /**&#10;     * Navigasi ke AttendanceScreen dari mana saja&#10;     */&#10;    fun navigateToAttendance() {&#10;        _navigationEvents.tryEmit(NavigationEvent.NavigateToAttendance)&#10;    }&#10;&#10;    /**&#10;     * Navigasi ke screen lain jika diperlukan&#10;     */&#10;    fun navigateToScreen(route: String) {&#10;        _navigationEvents.tryEmit(NavigationEvent.NavigateToScreen(route))&#10;    }&#10;}&#10;&#10;/**&#10; * Event untuk navigasi&#10; */&#10;sealed class NavigationEvent {&#10;    object NavigateToAttendance : NavigationEvent()&#10;    data class NavigateToScreen(val route: String) : NavigationEvent()&#10;}&#10;" />
              <option name="updatedContent" value="package com.example.infinite_track.presentation.navigation&#10;&#10;import kotlinx.coroutines.flow.MutableSharedFlow&#10;import kotlinx.coroutines.flow.asSharedFlow&#10;import javax.inject.Inject&#10;import javax.inject.Singleton&#10;&#10;/**&#10; * Singleton navigator untuk menangani navigasi dari luar Composable context&#10; * Useful untuk navigasi dari Activity, BroadcastReceiver, atau Service&#10; */&#10;@Singleton&#10;class AppNavigator @Inject constructor() {&#10;&#10;    private val _navigationEvents = MutableSharedFlow&lt;NavigationEvent&gt;()&#10;    val navigationEvents = _navigationEvents.asSharedFlow()&#10;&#10;    /**&#10;     * Navigasi ke AttendanceScreen dari mana saja&#10;     */&#10;    fun navigateToAttendance() {&#10;        _navigationEvents.tryEmit(NavigationEvent.NavigateToAttendance)&#10;    }&#10;&#10;    /**&#10;     * Navigasi ke screen lain jika diperlukan&#10;     */&#10;    fun navigateToScreen(route: String) {&#10;        _navigationEvents.tryEmit(NavigationEvent.NavigateToScreen(route))&#10;    }&#10;&#10;    /**&#10;     * Navigasi ke login setelah sesi berakhir (401 error)&#10;     */&#10;    fun navigateToLoginAfterSessionExpired() {&#10;        _navigationEvents.tryEmit(NavigationEvent.NavigateToLoginAfterSessionExpired)&#10;    }&#10;}&#10;&#10;/**&#10; * Event untuk navigasi&#10; */&#10;sealed class NavigationEvent {&#10;    object NavigateToAttendance : NavigationEvent()&#10;    data class NavigateToScreen(val route: String) : NavigationEvent()&#10;    object NavigateToLoginAfterSessionExpired : NavigationEvent()&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/presentation/screen/attendance/face/FaceScannerViewModel.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/presentation/screen/attendance/face/FaceScannerViewModel.kt" />
              <option name="originalContent" value="package com.example.infinite_track.presentation.screen.attendance.face&#10;&#10;import android.graphics.Bitmap&#10;import androidx.camera.core.ImageProxy&#10;import androidx.compose.ui.geometry.Rect&#10;import androidx.compose.ui.geometry.Size&#10;import androidx.lifecycle.ViewModel&#10;import androidx.lifecycle.viewModelScope&#10;import com.example.infinite_track.data.face.FaceDetectorHelper&#10;import com.example.infinite_track.domain.use_case.auth.VerifyFaceUseCase&#10;import com.google.mlkit.vision.face.Face&#10;import dagger.hilt.android.lifecycle.HiltViewModel&#10;import kotlinx.coroutines.Job&#10;import kotlinx.coroutines.delay&#10;import kotlinx.coroutines.flow.MutableStateFlow&#10;import kotlinx.coroutines.flow.StateFlow&#10;import kotlinx.coroutines.flow.asStateFlow&#10;import kotlinx.coroutines.launch&#10;import javax.inject.Inject&#10;&#10;/**&#10; * Enum untuk tantangan liveness detection&#10; */&#10;enum class LivenessChallenge {&#10;    BLINK, SMILE&#10;}&#10;&#10;/**&#10; * Enum untuk status proses liveness detection&#10; */&#10;enum class LivenessState {&#10;    IDLE,&#10;    DETECTING_FACE,&#10;    WAITING_FOR_LIVENESS,&#10;    LIVENESS_DETECTED,&#10;    VERIFYING_FACE,&#10;    SUCCESS,&#10;    FAILURE,&#10;    TIMEOUT&#10;}&#10;&#10;/**&#10; * Data class untuk state lengkap face scanner&#10; */&#10;data class FaceScannerState(&#10;    val livenessState: LivenessState = LivenessState.IDLE,&#10;    val currentChallenge: LivenessChallenge = LivenessChallenge.BLINK,&#10;    val instructionText: String = &quot;&quot;,&#10;    val boundingBox: Rect? = null, // Changed to androidx.compose.ui.geometry.Rect&#10;    val progress: Float = 0f,&#10;    val errorMessage: String? = null,&#10;    val isProcessing: Boolean = false,&#10;    val timeRemaining: Int = 20, // 20 detik sesuai kebutuhan&#10;    val showCountdown: Boolean = false,&#10;    val imageSize: Size? = null // Add image size for coordinate scaling&#10;)&#10;&#10;/**&#10; * ViewModel untuk mengatur logika face scanning dengan liveness detection&#10; */&#10;@HiltViewModel&#10;class FaceScannerViewModel @Inject constructor(&#10;    private val faceDetectorHelper: FaceDetectorHelper,&#10;    private val verifyFaceUseCase: VerifyFaceUseCase&#10;) : ViewModel() {&#10;&#10;    companion object {&#10;        private const val TIMEOUT_SECONDS = 20&#10;        private const val LIVENESS_HOLD_DURATION = 1500L // 1.5 detik hold untuk stabilitas&#10;    }&#10;&#10;    // Change from mutableStateOf to StateFlow for better compatibility&#10;    private val _uiState = MutableStateFlow(FaceScannerState())&#10;    val uiState: StateFlow&lt;FaceScannerState&gt; = _uiState.asStateFlow()&#10;&#10;    private var timeoutJob: Job? = null&#10;    private var livenessJob: Job? = null&#10;    private var currentDetectedFace: Face? = null&#10;    private var currentImageBitmap: Bitmap? = null&#10;&#10;    init {&#10;        initializeScanner()&#10;    }&#10;&#10;    /**&#10;     * Inisialisasi scanner dengan random challenge&#10;     */&#10;    private fun initializeScanner() {&#10;        // Pilih challenge secara acak&#10;        val randomChallenge = if ((0..1).random() == 0) {&#10;            LivenessChallenge.BLINK&#10;        } else {&#10;            LivenessChallenge.SMILE&#10;        }&#10;&#10;        val instructionText = when (randomChallenge) {&#10;            LivenessChallenge.BLINK -&gt; &quot;Posisikan wajah Anda di dalam frame, lalu kedipkan mata&quot;&#10;            LivenessChallenge.SMILE -&gt; &quot;Posisikan wajah Anda di dalam frame, lalu tersenyum&quot;&#10;        }&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            currentChallenge = randomChallenge,&#10;            instructionText = instructionText,&#10;            livenessState = LivenessState.DETECTING_FACE,&#10;            timeRemaining = TIMEOUT_SECONDS,&#10;            showCountdown = true,&#10;            isProcessing = false,&#10;            errorMessage = null,&#10;            boundingBox = null,&#10;            progress = 0f&#10;        )&#10;&#10;        startTimeout()&#10;    }&#10;&#10;    /**&#10;     * Proses frame dari kamera untuk deteksi wajah dan verifikasi liveness&#10;     */&#10;    fun processImageProxy(imageProxy: ImageProxy, imageBitmap: Bitmap) {&#10;        // Jangan proses jika sedang dalam proses atau sudah timeout/selesai&#10;        if (_uiState.value.isProcessing ||&#10;            _uiState.value.livenessState == LivenessState.SUCCESS ||&#10;            _uiState.value.livenessState == LivenessState.TIMEOUT ||&#10;            _uiState.value.livenessState == LivenessState.FAILURE&#10;        ) {&#10;            imageProxy.close()&#10;            return&#10;        }&#10;&#10;        currentImageBitmap = imageBitmap&#10;&#10;        // Panggil FaceDetectorHelper untuk mendeteksi wajah&#10;        faceDetectorHelper.detect(imageProxy) { result -&gt;&#10;            result.onSuccess { face -&gt;&#10;                handleFaceDetected(face, imageBitmap.width, imageBitmap.height)&#10;            }.onFailure { exception -&gt;&#10;                handleFaceDetectionError(exception.message ?: &quot;Error mendeteksi wajah&quot;)&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Handle ketika wajah berhasil terdeteksi&#10;     */&#10;    private fun handleFaceDetected(face: Face, imageWidth: Int, imageHeight: Int) {&#10;        currentDetectedFace = face&#10;&#10;        // Convert android.graphics.Rect to androidx.compose.ui.geometry.Rect&#10;        val androidRect = face.boundingBox&#10;        val composeRect = Rect(&#10;            left = androidRect.left.toFloat(),&#10;            top = androidRect.top.toFloat(),&#10;            right = androidRect.right.toFloat(),&#10;            bottom = androidRect.bottom.toFloat()&#10;        )&#10;&#10;        // Update bounding box dan image size untuk UI dengan coordinate scaling yang proper&#10;        _uiState.value = _uiState.value.copy(&#10;            boundingBox = composeRect,&#10;            imageSize = Size(&#10;                width = imageWidth.toFloat(),&#10;                height = imageHeight.toFloat()&#10;            )&#10;        )&#10;&#10;        // Debug log untuk melihat koordinat&#10;        println(&quot;Face detected - Android Rect: $androidRect&quot;)&#10;        println(&quot;Face detected - Compose Rect: $composeRect&quot;)&#10;        println(&quot;Image size: ${imageWidth}x${imageHeight}&quot;)&#10;&#10;        // Cek apakah wajah berada di posisi yang baik&#10;        if (!faceDetectorHelper.isFaceWellPositioned(face, imageWidth, imageHeight)) {&#10;            _uiState.value = _uiState.value.copy(&#10;                livenessState = LivenessState.DETECTING_FACE,&#10;                instructionText = &quot;Posisikan wajah Anda lebih dekat dan di tengah frame&quot;&#10;            )&#10;            return&#10;        }&#10;&#10;        // Wajah sudah di posisi yang baik, lanjut ke pengecekan liveness&#10;        when (_uiState.value.livenessState) {&#10;            LivenessState.DETECTING_FACE -&gt; {&#10;                // Transisi ke waiting for liveness&#10;                _uiState.value = _uiState.value.copy(&#10;                    livenessState = LivenessState.WAITING_FOR_LIVENESS,&#10;                    instructionText = when (_uiState.value.currentChallenge) {&#10;                        LivenessChallenge.BLINK -&gt; &quot;Wajah terdeteksi! Sekarang kedipkan mata Anda&quot;&#10;                        LivenessChallenge.SMILE -&gt; &quot;Wajah terdeteksi! Sekarang tersenyum&quot;&#10;                    }&#10;                )&#10;            }&#10;&#10;            LivenessState.WAITING_FOR_LIVENESS -&gt; {&#10;                // Cek apakah challenge liveness terpenuhi&#10;                checkLivenessChallenge(face)&#10;            }&#10;&#10;            else -&gt; {&#10;                // State lain tidak perlu di-handle di sini&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Cek apakah challenge liveness saat ini terpenuhi&#10;     */&#10;    private fun checkLivenessChallenge(face: Face) {&#10;        val isLivenessDetected = when (_uiState.value.currentChallenge) {&#10;            LivenessChallenge.BLINK -&gt; faceDetectorHelper.verifyBlink(face)&#10;            LivenessChallenge.SMILE -&gt; faceDetectorHelper.verifySmile(face)&#10;        }&#10;&#10;        if (isLivenessDetected) {&#10;            _uiState.value = _uiState.value.copy(&#10;                livenessState = LivenessState.LIVENESS_DETECTED,&#10;                instructionText = &quot;Liveness terdeteksi! Tetap di posisi...&quot;&#10;            )&#10;&#10;            // Tahan deteksi sebentar untuk stabilitas, lalu lanjut verifikasi&#10;            livenessJob?.cancel()&#10;            livenessJob = viewModelScope.launch {&#10;                delay(LIVENESS_HOLD_DURATION)&#10;                proceedWithFaceVerification()&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Lanjutkan dengan verifikasi wajah setelah liveness terkonfirmasi&#10;     */&#10;    private fun proceedWithFaceVerification() {&#10;        val face = currentDetectedFace&#10;        val bitmap = currentImageBitmap&#10;&#10;        if (face == null || bitmap == null) {&#10;            handleVerificationError(&quot;Gagal mengambil data wajah&quot;)&#10;            return&#10;        }&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            livenessState = LivenessState.VERIFYING_FACE,&#10;            isProcessing = true,&#10;            instructionText = &quot;Memverifikasi identitas Anda...&quot;,&#10;            showCountdown = false&#10;        )&#10;&#10;        viewModelScope.launch {&#10;            try {&#10;                // Ekstrak bitmap wajah dari gambar penuh&#10;                val faceBitmap = faceDetectorHelper.extractFaceBitmap(face, bitmap)&#10;&#10;                if (faceBitmap == null) {&#10;                    handleVerificationError(&quot;Gagal mengekstrak wajah dari gambar&quot;)&#10;                    return@launch&#10;                }&#10;&#10;                // Verifikasi wajah menggunakan VerifyFaceUseCase&#10;                verifyFaceUseCase(faceBitmap)&#10;                    .onSuccess { isMatch -&gt;&#10;                        if (isMatch) {&#10;                            handleVerificationSuccess()&#10;                        } else {&#10;                            handleVerificationError(&quot;Wajah tidak cocok dengan data yang tersimpan. Silakan coba lagi.&quot;)&#10;                        }&#10;                    }&#10;                    .onFailure { exception -&gt;&#10;                        handleVerificationError(&#10;                            exception.message ?: &quot;Gagal memverifikasi wajah. Silakan coba lagi.&quot;&#10;                        )&#10;                    }&#10;&#10;            } catch (e: Exception) {&#10;                handleVerificationError(&quot;Terjadi kesalahan: ${e.message}&quot;)&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Handle sukses verifikasi wajah&#10;     */&#10;    private fun handleVerificationSuccess() {&#10;        timeoutJob?.cancel()&#10;        livenessJob?.cancel()&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            livenessState = LivenessState.SUCCESS,&#10;            isProcessing = false,&#10;            instructionText = &quot;Verifikasi berhasil! Identitas terkonfirmasi.&quot;,&#10;            progress = 1f,&#10;            showCountdown = false,&#10;            errorMessage = null&#10;        )&#10;    }&#10;&#10;    /**&#10;     * Handle error deteksi wajah&#10;     */&#10;    private fun handleFaceDetectionError(errorMessage: String) {&#10;        // Hanya update instruction jika masih dalam tahap deteksi&#10;        if (_uiState.value.livenessState == LivenessState.DETECTING_FACE) {&#10;            _uiState.value = _uiState.value.copy(&#10;                instructionText = &quot;Mencari wajah... Pastikan wajah terlihat jelas di dalam frame&quot;,&#10;                boundingBox = null&#10;            )&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Handle error verifikasi wajah&#10;     */&#10;    private fun handleVerificationError(errorMessage: String) {&#10;        timeoutJob?.cancel()&#10;        livenessJob?.cancel()&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            livenessState = LivenessState.FAILURE,&#10;            isProcessing = false,&#10;            instructionText = &quot;Verifikasi gagal&quot;,&#10;            errorMessage = errorMessage,&#10;            showCountdown = false&#10;        )&#10;    }&#10;&#10;    /**&#10;     * Mulai countdown timer untuk timeout&#10;     */&#10;    private fun startTimeout() {&#10;        timeoutJob?.cancel()&#10;        timeoutJob = viewModelScope.launch {&#10;            repeat(TIMEOUT_SECONDS) { second -&gt;&#10;                val remainingTime = TIMEOUT_SECONDS - second&#10;                _uiState.value = _uiState.value.copy(&#10;                    timeRemaining = remainingTime,&#10;                    progress = second.toFloat() / TIMEOUT_SECONDS&#10;                )&#10;                delay(1000)&#10;&#10;                // Cek apakah proses sudah selesai&#10;                if (_uiState.value.livenessState == LivenessState.SUCCESS ||&#10;                    _uiState.value.livenessState == LivenessState.FAILURE&#10;                ) {&#10;                    return@launch&#10;                }&#10;            }&#10;&#10;            // Timeout tercapai&#10;            handleTimeout()&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Handle timeout&#10;     */&#10;    private fun handleTimeout() {&#10;        livenessJob?.cancel()&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            livenessState = LivenessState.TIMEOUT,&#10;            isProcessing = false,&#10;            instructionText = &quot;Waktu habis&quot;,&#10;            errorMessage = &quot;Tidak dapat mendeteksi wajah dalam waktu $TIMEOUT_SECONDS detik. Silakan coba lagi.&quot;,&#10;            showCountdown = false,&#10;            timeRemaining = 0&#10;        )&#10;    }&#10;&#10;    /**&#10;     * Reset scanner untuk mencoba lagi&#10;     */&#10;    fun resetScanner() {&#10;        timeoutJob?.cancel()&#10;        livenessJob?.cancel()&#10;        currentDetectedFace = null&#10;        currentImageBitmap = null&#10;&#10;        initializeScanner()&#10;    }&#10;&#10;    /**&#10;     * Bersihkan resources ketika ViewModel dihancurkan&#10;     */&#10;    override fun onCleared() {&#10;        super.onCleared()&#10;        timeoutJob?.cancel()&#10;        livenessJob?.cancel()&#10;        faceDetectorHelper.release()&#10;    }&#10;}&#10;" />
              <option name="updatedContent" value="package com.example.infinite_track.presentation.screen.attendance.face&#10;&#10;import android.graphics.Bitmap&#10;import androidx.camera.core.ImageProxy&#10;import androidx.compose.ui.geometry.Rect&#10;import androidx.compose.ui.geometry.Size&#10;import androidx.lifecycle.ViewModel&#10;import androidx.lifecycle.viewModelScope&#10;import com.example.infinite_track.data.face.FaceDetectorHelper&#10;import com.example.infinite_track.domain.use_case.auth.VerifyFaceUseCase&#10;import com.google.mlkit.vision.face.Face&#10;import dagger.hilt.android.lifecycle.HiltViewModel&#10;import kotlinx.coroutines.Job&#10;import kotlinx.coroutines.delay&#10;import kotlinx.coroutines.flow.MutableStateFlow&#10;import kotlinx.coroutines.flow.StateFlow&#10;import kotlinx.coroutines.flow.asStateFlow&#10;import kotlinx.coroutines.launch&#10;import javax.inject.Inject&#10;&#10;/**&#10; * Enum untuk tantangan liveness detection&#10; */&#10;enum class LivenessChallenge {&#10;    BLINK, SMILE&#10;}&#10;&#10;/**&#10; * Enum untuk status proses liveness detection&#10; */&#10;enum class LivenessState {&#10;    IDLE,&#10;    DETECTING_FACE,&#10;    WAITING_FOR_LIVENESS,&#10;    LIVENESS_DETECTED,&#10;    VERIFYING_FACE,&#10;    SUCCESS,&#10;    FAILURE,&#10;    TIMEOUT&#10;}&#10;&#10;/**&#10; * Data class untuk state lengkap face scanner&#10; */&#10;data class FaceScannerState(&#10;    val livenessState: LivenessState = LivenessState.IDLE,&#10;    val currentChallenge: LivenessChallenge = LivenessChallenge.BLINK,&#10;    val instructionText: String = &quot;&quot;,&#10;    val boundingBox: Rect? = null, // Changed to androidx.compose.ui.geometry.Rect&#10;    val progress: Float = 0f,&#10;    val errorMessage: String? = null,&#10;    val isProcessing: Boolean = false,&#10;    val timeRemaining: Int = 20, // 20 detik sesuai kebutuhan&#10;    val showCountdown: Boolean = false,&#10;    val imageSize: Size? = null // Add image size for coordinate scaling&#10;)&#10;&#10;/**&#10; * ViewModel untuk mengatur logika face scanning dengan liveness detection&#10; */&#10;@HiltViewModel&#10;class FaceScannerViewModel @Inject constructor(&#10;    private val faceDetectorHelper: FaceDetectorHelper,&#10;    private val verifyFaceUseCase: VerifyFaceUseCase&#10;) : ViewModel() {&#10;&#10;    companion object {&#10;        private const val TIMEOUT_SECONDS = 20&#10;        private const val LIVENESS_HOLD_DURATION = 1500L // 1.5 detik hold untuk stabilitas&#10;    }&#10;&#10;    // Change from mutableStateOf to StateFlow for better compatibility&#10;    private val _uiState = MutableStateFlow(FaceScannerState())&#10;    val uiState: StateFlow&lt;FaceScannerState&gt; = _uiState.asStateFlow()&#10;&#10;    private var timeoutJob: Job? = null&#10;    private var livenessJob: Job? = null&#10;    private var currentDetectedFace: Face? = null&#10;    private var currentImageBitmap: Bitmap? = null&#10;&#10;    init {&#10;        initializeScanner()&#10;    }&#10;&#10;    /**&#10;     * Inisialisasi scanner dengan random challenge&#10;     */&#10;    private fun initializeScanner() {&#10;        // Pilih challenge secara acak&#10;        val randomChallenge = if ((0..1).random() == 0) {&#10;            LivenessChallenge.BLINK&#10;        } else {&#10;            LivenessChallenge.SMILE&#10;        }&#10;&#10;        val instructionText = when (randomChallenge) {&#10;            LivenessChallenge.BLINK -&gt; &quot;Posisikan wajah Anda di dalam frame, lalu kedipkan mata&quot;&#10;            LivenessChallenge.SMILE -&gt; &quot;Posisikan wajah Anda di dalam frame, lalu tersenyum&quot;&#10;        }&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            currentChallenge = randomChallenge,&#10;            instructionText = instructionText,&#10;            livenessState = LivenessState.DETECTING_FACE,&#10;            timeRemaining = TIMEOUT_SECONDS,&#10;            showCountdown = true,&#10;            isProcessing = false,&#10;            errorMessage = null,&#10;            boundingBox = null,&#10;            progress = 0f&#10;        )&#10;&#10;        startTimeout()&#10;    }&#10;&#10;    /**&#10;     * Proses frame dari kamera untuk deteksi wajah dan verifikasi liveness&#10;     */&#10;    fun processImageProxy(imageProxy: ImageProxy, imageBitmap: Bitmap) {&#10;        // Jangan proses jika sedang dalam proses atau sudah timeout/selesai&#10;        if (_uiState.value.isProcessing ||&#10;            _uiState.value.livenessState == LivenessState.SUCCESS ||&#10;            _uiState.value.livenessState == LivenessState.TIMEOUT ||&#10;            _uiState.value.livenessState == LivenessState.FAILURE&#10;        ) {&#10;            imageProxy.close()&#10;            return&#10;        }&#10;&#10;        currentImageBitmap = imageBitmap&#10;&#10;        // Panggil FaceDetectorHelper untuk mendeteksi wajah&#10;        faceDetectorHelper.detect(imageProxy) { result -&gt;&#10;            result.onSuccess { face -&gt;&#10;                handleFaceDetected(face, imageBitmap.width, imageBitmap.height)&#10;            }.onFailure { exception -&gt;&#10;                handleFaceDetectionError(exception.message ?: &quot;Error mendeteksi wajah&quot;)&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Handle ketika wajah berhasil terdeteksi&#10;     */&#10;    private fun handleFaceDetected(face: Face, imageWidth: Int, imageHeight: Int) {&#10;        currentDetectedFace = face&#10;&#10;        // Convert android.graphics.Rect to androidx.compose.ui.geometry.Rect&#10;        val androidRect = face.boundingBox&#10;        val composeRect = Rect(&#10;            left = androidRect.left.toFloat(),&#10;            top = androidRect.top.toFloat(),&#10;            right = androidRect.right.toFloat(),&#10;            bottom = androidRect.bottom.toFloat()&#10;        )&#10;&#10;        // Update bounding box dan image size untuk UI dengan coordinate scaling yang proper&#10;        _uiState.value = _uiState.value.copy(&#10;            boundingBox = composeRect,&#10;            imageSize = Size(&#10;                width = imageWidth.toFloat(),&#10;                height = imageHeight.toFloat()&#10;            )&#10;        )&#10;&#10;        // Debug log untuk melihat koordinat&#10;        println(&quot;Face detected - Android Rect: $androidRect&quot;)&#10;        println(&quot;Face detected - Compose Rect: $composeRect&quot;)&#10;        println(&quot;Image size: ${imageWidth}x${imageHeight}&quot;)&#10;&#10;        // Cek apakah wajah berada di posisi yang baik&#10;        if (!faceDetectorHelper.isFaceWellPositioned(face, imageWidth, imageHeight)) {&#10;            _uiState.value = _uiState.value.copy(&#10;                livenessState = LivenessState.DETECTING_FACE,&#10;                instructionText = &quot;Posisikan wajah Anda lebih dekat dan di tengah frame&quot;&#10;            )&#10;            return&#10;        }&#10;&#10;        // Wajah sudah di posisi yang baik, lanjut ke pengecekan liveness&#10;        when (_uiState.value.livenessState) {&#10;            LivenessState.DETECTING_FACE -&gt; {&#10;                // Transisi ke waiting for liveness&#10;                _uiState.value = _uiState.value.copy(&#10;                    livenessState = LivenessState.WAITING_FOR_LIVENESS,&#10;                    instructionText = when (_uiState.value.currentChallenge) {&#10;                        LivenessChallenge.BLINK -&gt; &quot;Wajah terdeteksi! Sekarang kedipkan mata Anda&quot;&#10;                        LivenessChallenge.SMILE -&gt; &quot;Wajah terdeteksi! Sekarang tersenyum&quot;&#10;                    }&#10;                )&#10;            }&#10;&#10;            LivenessState.WAITING_FOR_LIVENESS -&gt; {&#10;                // Cek apakah challenge liveness terpenuhi&#10;                checkLivenessChallenge(face)&#10;            }&#10;&#10;            else -&gt; {&#10;                // State lain tidak perlu di-handle di sini&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Cek apakah challenge liveness saat ini terpenuhi&#10;     */&#10;    private fun checkLivenessChallenge(face: Face) {&#10;        val isLivenessDetected = when (_uiState.value.currentChallenge) {&#10;            LivenessChallenge.BLINK -&gt; faceDetectorHelper.verifyBlink(face)&#10;            LivenessChallenge.SMILE -&gt; faceDetectorHelper.verifySmile(face)&#10;        }&#10;&#10;        if (isLivenessDetected) {&#10;            _uiState.value = _uiState.value.copy(&#10;                livenessState = LivenessState.LIVENESS_DETECTED,&#10;                instructionText = &quot;Liveness terdeteksi! Tetap di posisi...&quot;&#10;            )&#10;&#10;            // Tahan deteksi sebentar untuk stabilitas, lalu lanjut verifikasi&#10;            livenessJob?.cancel()&#10;            livenessJob = viewModelScope.launch {&#10;                delay(LIVENESS_HOLD_DURATION)&#10;                proceedWithFaceVerification()&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Lanjutkan dengan verifikasi wajah setelah liveness terkonfirmasi&#10;     */&#10;    private fun proceedWithFaceVerification() {&#10;        val face = currentDetectedFace&#10;        val bitmap = currentImageBitmap&#10;&#10;        if (face == null || bitmap == null) {&#10;            handleVerificationError(&quot;Gagal mengambil data wajah&quot;)&#10;            return&#10;        }&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            livenessState = LivenessState.VERIFYING_FACE,&#10;            isProcessing = true,&#10;            instructionText = &quot;Memverifikasi identitas Anda...&quot;,&#10;            showCountdown = false&#10;        )&#10;&#10;        viewModelScope.launch {&#10;            try {&#10;                // DEBUG: Log bitmap info sebelum ekstraksi&#10;                println(&quot;DEBUG: Original bitmap size: ${bitmap.width}x${bitmap.height}&quot;)&#10;                println(&quot;DEBUG: Face bounding box: ${face.boundingBox}&quot;)&#10;                &#10;                // Ekstrak bitmap wajah dari gambar penuh&#10;                val faceBitmap = faceDetectorHelper.extractFaceBitmap(face, bitmap)&#10;&#10;                if (faceBitmap == null) {&#10;                    handleVerificationError(&quot;Gagal mengekstrak wajah dari gambar&quot;)&#10;                    return@launch&#10;                }&#10;&#10;                // DEBUG: Log face bitmap info setelah ekstraksi&#10;                println(&quot;DEBUG: Extracted face bitmap size: ${faceBitmap.width}x${faceBitmap.height}&quot;)&#10;                &#10;                // Verifikasi wajah menggunakan VerifyFaceUseCase&#10;                println(&quot;DEBUG: Starting face verification...&quot;)&#10;                verifyFaceUseCase(faceBitmap)&#10;                    .onSuccess { isMatch -&gt;&#10;                        println(&quot;DEBUG: Face verification completed. Match: $isMatch&quot;)&#10;                        if (isMatch) {&#10;                            handleVerificationSuccess()&#10;                        } else {&#10;                            handleVerificationError(&quot;Wajah tidak cocok dengan data yang tersimpan. Silakan coba lagi.&quot;)&#10;                        }&#10;                    }&#10;                    .onFailure { exception -&gt;&#10;                        println(&quot;DEBUG: Face verification failed with exception: ${exception.message}&quot;)&#10;                        handleVerificationError(&#10;                            exception.message ?: &quot;Gagal memverifikasi wajah. Silakan coba lagi.&quot;&#10;                        )&#10;                    }&#10;&#10;            } catch (e: Exception) {&#10;                println(&quot;DEBUG: Exception in proceedWithFaceVerification: ${e.message}&quot;)&#10;                handleVerificationError(&quot;Terjadi kesalahan: ${e.message}&quot;)&#10;            }&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Handle sukses verifikasi wajah&#10;     */&#10;    private fun handleVerificationSuccess() {&#10;        timeoutJob?.cancel()&#10;        livenessJob?.cancel()&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            livenessState = LivenessState.SUCCESS,&#10;            isProcessing = false,&#10;            instructionText = &quot;Verifikasi berhasil! Identitas terkonfirmasi.&quot;,&#10;            progress = 1f,&#10;            showCountdown = false,&#10;            errorMessage = null&#10;        )&#10;    }&#10;&#10;    /**&#10;     * Handle error deteksi wajah&#10;     */&#10;    private fun handleFaceDetectionError(errorMessage: String) {&#10;        // Hanya update instruction jika masih dalam tahap deteksi&#10;        if (_uiState.value.livenessState == LivenessState.DETECTING_FACE) {&#10;            _uiState.value = _uiState.value.copy(&#10;                instructionText = &quot;Mencari wajah... Pastikan wajah terlihat jelas di dalam frame&quot;,&#10;                boundingBox = null&#10;            )&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Handle error verifikasi wajah&#10;     */&#10;    private fun handleVerificationError(errorMessage: String) {&#10;        timeoutJob?.cancel()&#10;        livenessJob?.cancel()&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            livenessState = LivenessState.FAILURE,&#10;            isProcessing = false,&#10;            instructionText = &quot;Verifikasi gagal&quot;,&#10;            errorMessage = errorMessage,&#10;            showCountdown = false&#10;        )&#10;    }&#10;&#10;    /**&#10;     * Mulai countdown timer untuk timeout&#10;     */&#10;    private fun startTimeout() {&#10;        timeoutJob?.cancel()&#10;        timeoutJob = viewModelScope.launch {&#10;            repeat(TIMEOUT_SECONDS) { second -&gt;&#10;                val remainingTime = TIMEOUT_SECONDS - second&#10;                _uiState.value = _uiState.value.copy(&#10;                    timeRemaining = remainingTime,&#10;                    progress = second.toFloat() / TIMEOUT_SECONDS&#10;                )&#10;                delay(1000)&#10;&#10;                // Cek apakah proses sudah selesai&#10;                if (_uiState.value.livenessState == LivenessState.SUCCESS ||&#10;                    _uiState.value.livenessState == LivenessState.FAILURE&#10;                ) {&#10;                    return@launch&#10;                }&#10;            }&#10;&#10;            // Timeout tercapai&#10;            handleTimeout()&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Handle timeout&#10;     */&#10;    private fun handleTimeout() {&#10;        livenessJob?.cancel()&#10;&#10;        _uiState.value = _uiState.value.copy(&#10;            livenessState = LivenessState.TIMEOUT,&#10;            isProcessing = false,&#10;            instructionText = &quot;Waktu habis&quot;,&#10;            errorMessage = &quot;Tidak dapat mendeteksi wajah dalam waktu $TIMEOUT_SECONDS detik. Silakan coba lagi.&quot;,&#10;            showCountdown = false,&#10;            timeRemaining = 0&#10;        )&#10;    }&#10;&#10;    /**&#10;     * Reset scanner untuk mencoba lagi&#10;     */&#10;    fun resetScanner() {&#10;        timeoutJob?.cancel()&#10;        livenessJob?.cancel()&#10;        currentDetectedFace = null&#10;        currentImageBitmap = null&#10;&#10;        initializeScanner()&#10;    }&#10;&#10;    /**&#10;     * Bersihkan resources ketika ViewModel dihancurkan&#10;     */&#10;    override fun onCleared() {&#10;        super.onCleared()&#10;        timeoutJob?.cancel()&#10;        livenessJob?.cancel()&#10;        faceDetectorHelper.release()&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>